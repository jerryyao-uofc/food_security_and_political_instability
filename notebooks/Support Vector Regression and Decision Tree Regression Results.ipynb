{"cells":[{"cell_type":"markdown","source":["# Load the Data"],"metadata":{"id":"8qIVeXG2G1cz"},"id":"8qIVeXG2G1cz"},{"cell_type":"code","execution_count":1,"id":"0a1b7081","metadata":{"id":"0a1b7081","executionInfo":{"status":"ok","timestamp":1653237902908,"user_tz":300,"elapsed":1430,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}}},"outputs":[],"source":["# basic package\n","import csv\n","import glob\n","import pandas as pd\n","import matplotlib as plt\n","from tqdm import tqdm\n","import numpy as np\n","import random\n","from operator import itemgetter\n","import matplotlib.pyplot as plt\n","import warnings\n","\n","\n","# ml related \n","from sklearn import linear_model\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn import svm\n","from sklearn.tree import DecisionTreeRegressor"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQPiPht8f4jb","executionInfo":{"status":"ok","timestamp":1653237925350,"user_tz":300,"elapsed":22444,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}},"outputId":"45e55597-3a97-4107-8ccd-c5b29d76c6a6"},"id":"IQPiPht8f4jb","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"id":"a99c8ab4","metadata":{"id":"a99c8ab4","executionInfo":{"status":"ok","timestamp":1653237935418,"user_tz":300,"elapsed":7954,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}}},"outputs":[],"source":["political = pd.read_csv(\"drive/Shareddrives/ML_&_Econometrics/Merged/political_selected.csv\")\n","undernourish = pd.read_csv(\"drive/Shareddrives/ML_&_Econometrics/Merged/undernourish_selected.csv\")\n","# drinking = pd.read_csv(\"drive/Shareddrives/ML_&_Econometrics/Merged/drinking_selected.csv\")\n","\n","meaning_map = pd.read_csv(\"drive/Shareddrives/ML_&_Econometrics/Merged/final_new_meaning_A.csv\")"]},{"cell_type":"markdown","source":["# Preparatory Code"],"metadata":{"id":"21vGmDxJGp3m"},"id":"21vGmDxJGp3m"},{"cell_type":"code","source":["\n","def map_code_to_meaning(mapping, code_no):\n","    return (mapping.loc[mapping['code']==code_no]).iloc[0].var_name\n","\n","# print the total percetnage of missing in each dataset\n","def total_percentage_missing(df):\n","    return(np.count_nonzero(df.isna()) / df.size)\n","\n","# drop the top N rows with most NAs\n","def drop_top_N_rows_with_most_NAs(df, N=300):\n","    if N/len(df)> 0.2:\n","      warnings.warn(\"Based on your speficied N, you are dropping more then 20% of the data\")\n","\n","    print(\"shape before drop\", df.shape)\n","    dict_nas = {}\n","    for i in range(len(df)):\n","        percentage = total_percentage_missing(df.iloc[i])\n","        dict_nas[i] = percentage\n","    res = dict(sorted(dict_nas.items(), key = itemgetter(1), reverse = True)[:N])\n","    # print(\"here\")\n","    top_NAs_rows = list(res.keys())\n","    # print(top_NAs_rows)\n","    df.drop(top_NAs_rows, axis=0, inplace=True)\n","    print(\"shape after drop \", df.shape)\n","    print(\"Missing data percentage \", total_percentage_missing(df) )\n","    return df\n","\n","# split into two dataset by year (default=2017)\n","# fist one include that year, second one is year after that\n","def split_by_year(df, split_at = 2017):\n","    res1 = df.loc[df['Year']<= split_at]\n","    res2 = df.loc[df['Year']> split_at]\n","    return res1, res2\n","\n","def print_all_coeff(list_coef, feature_name):\n","    sort_index = reversed(np.argsort(list_coef))\n","    list_of_lists = []\n","    for i in sort_index:\n","#         print(feature_name[i])\n","        temp = int(feature_name[i])\n","        if list_coef[i] !=0.0:\n","            list_of_lists.append([round(list_coef[i],10), feature_name[i], map_code_to_meaning(meaning_map, temp)])\n","    return pd.DataFrame(list_of_lists, columns =['non_zero_coefficient', 'code', 'variable_name'])\n","\n"],"metadata":{"id":"P3pVMmdrGmMv","executionInfo":{"status":"ok","timestamp":1653237935418,"user_tz":300,"elapsed":4,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}}},"id":"P3pVMmdrGmMv","execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"3ced5b79","metadata":{"id":"3ced5b79"},"outputs":[],"source":["  # pipeline on returning the coefficient of lasso regression\n","# also returns the score of the regressions\n","def lasso_pipeline(df, target_name = 'political', split_year = 2017, lasso_alpha = 0.12):\n","\n","    if target_name not in df.columns:\n","        raise ValueError(\"The input dataframe doesn't have the column: political\")\n","    \n","    if 'Continent' in df.columns:\n","      df = df.drop(columns =['Continent'])\n","\n","    # default split at 2017\n","    political_pre_2017, political_post_2017 = split_by_year(df, split_at = split_year)\n","    \n","    # Note, the variable names here is only names, y_politcal can be any dataframe\n","    # doesn't have to be political \n","    y_political = political_pre_2017.pop(target_name)\n","    X_political = political_pre_2017.drop(columns = ['Year', 'Area Code'])\n","\n","    y_political_test = political_post_2017.pop(target_name)\n","    X_political_test = political_post_2017.drop(columns = ['Year', 'Area Code'])\n","\n","    \n","    feature_names = X_political_test.columns\n","\n","    # scale the X\n","    scaler = StandardScaler()\n","    political_scaler_X = scaler.fit(X_political)\n","    X_political_scaled = political_scaler_X.transform(X_political)\n","    X_political_test_scaled = political_scaler_X.transform(X_political_test)\n","\n","    # scale the y\n","    y_political = y_political.values.reshape(-1,1)\n","    y_political_test = y_political_test.values.reshape(-1,1)\n","    political_scaler_y = scaler.fit(y_political)\n","    y_political_scaled = political_scaler_y.transform(y_political)\n","    y_political_test_scaled = political_scaler_y.transform(y_political_test)\n","    \n","    # print shapes\n","    print(\"Training Shape:\", X_political_scaled.shape)\n","    print(\"Testing Shape\", X_political_test_scaled.shape)\n","    \n","    # Run LASSO\n","    reg = linear_model.Lasso(alpha=lasso_alpha).fit(X_political_scaled, y_political_scaled)\n","\n","    # evaluation\n","    print(\"score on training dataset\", reg.score(X_political_scaled, y_political_scaled) )\n","    print(\"score on testing dataset\", reg.score(X_political_test_scaled, y_political_test_scaled))\n","    y_train_pred = reg.predict(X_political_scaled) # predicting for training\n","    y_pred = reg.predict(X_political_test_scaled)  # predicting for testing\n","    print(\"R squared score on training\", r2_score(y_political_scaled, y_train_pred))\n","    print(\"R squared score on testing\", r2_score(y_political_test_scaled, y_pred))\n","    \n","    print(\"Mean Absolute Error on training\", mean_absolute_error(y_political_scaled, y_train_pred))\n","    print(\"Mean Absolute Error on testing\", mean_absolute_error(y_political_test_scaled, y_pred))\n","    res_df = print_all_coeff(reg.coef_, feature_names)\n","    return res_df"]},{"cell_type":"markdown","source":["# Support Vector Machine Code"],"metadata":{"id":"EGQ8z-3A3gos"},"id":"EGQ8z-3A3gos"},{"cell_type":"code","source":["  # pipeline on returning the coefficient of lasso regression\n","# also returns the score of the regressions\n","def support_vecotr_regression(df, target_name = 'political', split_year = 2017):\n","\n","    if target_name not in df.columns:\n","        raise ValueError(\"The input dataframe doesn't have the column: political\")\n","    \n","    if 'Continent' in df.columns:\n","      df = df.drop(columns =['Continent'])\n","\n","    # default split at 2017\n","    political_pre_2017, political_post_2017 = split_by_year(df, split_at = split_year)\n","    \n","    # Note, the variable names here is only names, y_politcal can be any dataframe\n","    # doesn't have to be political \n","    y_political = political_pre_2017.pop(target_name)\n","    X_political = political_pre_2017.drop(columns = ['Year', 'Area Code'])\n","\n","    y_political_test = political_post_2017.pop(target_name)\n","    X_political_test = political_post_2017.drop(columns = ['Year', 'Area Code'])\n","\n","    \n","    feature_names = X_political_test.columns\n","\n","    # scale the X\n","    scaler = StandardScaler()\n","    political_scaler_X = scaler.fit(X_political)\n","    X_political_scaled = political_scaler_X.transform(X_political)\n","    X_political_test_scaled = political_scaler_X.transform(X_political_test)\n","\n","    # scale the y\n","    y_political = y_political.values.reshape(-1,1)\n","    y_political_test = y_political_test.values.reshape(-1,1)\n","    political_scaler_y = scaler.fit(y_political)\n","    y_political_scaled = political_scaler_y.transform(y_political)\n","    y_political_test_scaled = political_scaler_y.transform(y_political_test)\n","    \n","    # print shapes\n","    print(\"Training Shape:\", X_political_scaled.shape)\n","    print(\"Testing Shape\", X_political_test_scaled.shape)\n","    \n","    # Run LASSO\n","    reg = svm.SVR().fit(X_political_scaled, y_political_scaled.ravel())\n","\n","    # evaluation\n","    \n","    y_train_pred = reg.predict(X_political_scaled) # predicting for training\n","    y_pred = reg.predict(X_political_test_scaled)  # predicting for testing\n"," \n","    print(\"Mean Absolute Error on training\", mean_absolute_error(y_political_scaled, y_train_pred))\n","    print(\"Mean Absolute Error on testing\", mean_absolute_error(y_political_test_scaled, y_pred))\n","    # res_df = print_all_coeff(reg.coef_, feature_names)\n","    return "],"metadata":{"id":"QAFmQIxetS7x","executionInfo":{"status":"ok","timestamp":1653237947915,"user_tz":300,"elapsed":292,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}}},"id":"QAFmQIxetS7x","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Decision Tree Regression "],"metadata":{"id":"Km3NiylF3k4p"},"id":"Km3NiylF3k4p"},{"cell_type":"code","source":["  # pipeline on returning the coefficient of lasso regression\n","# also returns the score of the regressions\n","def decision_tree_regression(df, target_name = 'political', split_year = 2017 ,max_depth = 20):\n","\n","    if target_name not in df.columns:\n","        raise ValueError(\"The input dataframe doesn't have the column: political\")\n","    \n","    if 'Continent' in df.columns:\n","      df = df.drop(columns =['Continent'])\n","\n","    # default split at 2017\n","    political_pre_2017, political_post_2017 = split_by_year(df, split_at = split_year)\n","    \n","    # Note, the variable names here is only names, y_politcal can be any dataframe\n","    # doesn't have to be political \n","    y_political = political_pre_2017.pop(target_name)\n","    X_political = political_pre_2017.drop(columns = ['Year', 'Area Code'])\n","\n","    y_political_test = political_post_2017.pop(target_name)\n","    X_political_test = political_post_2017.drop(columns = ['Year', 'Area Code'])\n","\n","    \n","    feature_names = X_political_test.columns\n","\n","    # scale the X\n","    scaler = StandardScaler()\n","    political_scaler_X = scaler.fit(X_political)\n","    X_political_scaled = political_scaler_X.transform(X_political)\n","    X_political_test_scaled = political_scaler_X.transform(X_political_test)\n","\n","    # scale the y\n","    y_political = y_political.values.reshape(-1,1)\n","    y_political_test = y_political_test.values.reshape(-1,1)\n","    political_scaler_y = scaler.fit(y_political)\n","    y_political_scaled = political_scaler_y.transform(y_political)\n","    y_political_test_scaled = political_scaler_y.transform(y_political_test)\n","    \n","    # print shapes\n","    print(\"Training Shape:\", X_political_scaled.shape)\n","    print(\"Testing Shape\", X_political_test_scaled.shape)\n","    \n","    # Run LASSO\n","    reg = DecisionTreeRegressor(max_depth=max_depth).fit(X_political_scaled, y_political_scaled.ravel())\n","\n","    # evaluation\n","\n","    y_train_pred = reg.predict(X_political_scaled) # predicting for training\n","    y_pred = reg.predict(X_political_test_scaled)  # predicting for testing\n","    \n","    \n","    print(\"Mean Absolute Error on training\", mean_absolute_error(y_political_scaled, y_train_pred))\n","    print(\"Mean Absolute Error on testing\", mean_absolute_error(y_political_test_scaled, y_pred))\n","    # res_df = print_all_coeff(reg.coef_, feature_names)\n","    return "],"metadata":{"id":"MDQ81FP03kFz","executionInfo":{"status":"ok","timestamp":1653237956833,"user_tz":300,"elapsed":267,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}}},"id":"MDQ81FP03kFz","execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Process Data Before Feeding in Pipeline: check missing data and fill in NAs"],"metadata":{"id":"Dj9X0blNgalJ"},"id":"Dj9X0blNgalJ"},{"cell_type":"code","execution_count":7,"id":"083aa2b3","metadata":{"scrolled":true,"id":"083aa2b3","outputId":"e4f692be-95f2-498f-ba4c-2a1f00bb622e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653237967874,"user_tz":300,"elapsed":4756,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["shape before drop (3705, 1002)\n","shape after drop  (3405, 1002)\n","Missing data percentage  0.003907896395168547\n","shape before drop (3933, 1002)\n","shape after drop  (3633, 1002)\n","Missing data percentage  0.02336230374373741\n"]}],"source":["# this chunck can only be run once\n","political = drop_top_N_rows_with_most_NAs(df= political, N= 300)\n","undernourish = drop_top_N_rows_with_most_NAs(df= undernourish, N= 300)\n","# drinking = drop_top_N_rows_with_most_NAs(df= drinking, N= 500)\n","\n","\n","\n","# fill NAs\n","political = political.fillna(0)\n","undernourish = undernourish.fillna(0)\n","# drinking = drinking.fillna(0)"]},{"cell_type":"markdown","source":["# Support Vector Regression"],"metadata":{"id":"Cfvf8jFZtgjN"},"id":"Cfvf8jFZtgjN"},{"cell_type":"code","source":["support_vecotr_regression(political, target_name = 'political')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2vJfRGEttika","executionInfo":{"status":"ok","timestamp":1653237982325,"user_tz":300,"elapsed":11283,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}},"outputId":"9313d930-51ff-4ef4-da6c-40669ffa650c"},"id":"2vJfRGEttika","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Shape: (3041, 999)\n","Testing Shape (364, 999)\n","Mean Absolute Error on training 0.23055096830644548\n","Mean Absolute Error on testing 0.3406512413374449\n"]}]},{"cell_type":"code","source":["support_vecotr_regression(undernourish, target_name = 'undernourish')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43A5mIOavykL","executionInfo":{"status":"ok","timestamp":1653238023742,"user_tz":300,"elapsed":10056,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}},"outputId":"b1141aea-761d-4405-d654-58bbfded4f87"},"id":"43A5mIOavykL","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Shape: (3055, 999)\n","Testing Shape (578, 999)\n","Mean Absolute Error on training 0.266560696538705\n","Mean Absolute Error on testing 0.599100448409452\n"]}]},{"cell_type":"markdown","source":["# Decision Tree Regression"],"metadata":{"id":"4ZcGC02f35j0"},"id":"4ZcGC02f35j0"},{"cell_type":"code","source":["decision_tree_regression(political, target_name = 'political', max_depth = 90)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9re0_DJf38A2","executionInfo":{"status":"ok","timestamp":1653238154494,"user_tz":300,"elapsed":5516,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}},"outputId":"a09e21cb-a412-49a5-9d09-16448b67a1c9"},"id":"9re0_DJf38A2","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Shape: (3041, 999)\n","Testing Shape (364, 999)\n","Mean Absolute Error on training 1.0952545458321176e-19\n","Mean Absolute Error on testing 0.23504383696472933\n"]}]},{"cell_type":"code","source":["decision_tree_regression(undernourish, target_name = 'undernourish', max_depth = 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JWHU1A5B6Kee","executionInfo":{"status":"ok","timestamp":1653238455438,"user_tz":300,"elapsed":3250,"user":{"displayName":"Jerry Yao","userId":"04157647443539114683"}},"outputId":"791c5f7b-1901-4903-f198-f945866e2bbf"},"id":"JWHU1A5B6Kee","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Shape: (3055, 999)\n","Testing Shape (578, 999)\n","Mean Absolute Error on training 1.8423160796521215e-16\n","Mean Absolute Error on testing 0.23042553189900747\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"vbpkKaKAqvLj"},"id":"vbpkKaKAqvLj","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Support Vector Regression and Decision Tree Regression Results.ipynb","provenance":[{"file_id":"1VslBKb1NW5hAD2eEg3VUImlHNomalXp8","timestamp":1652933166086}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}